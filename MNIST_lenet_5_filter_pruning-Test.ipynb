{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:30:47.515607Z",
     "start_time": "2019-04-03T00:30:41.342682Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from kerassurgeon import identify\n",
    "from kerassurgeon.operations import delete_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:30:48.100441Z",
     "start_time": "2019-04-03T00:30:47.517521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-1435084fbf27>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-1435084fbf27>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tempData\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tempData\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tempData\\t10k-images-idx3-ubyte.gz\n",
      "Extracting tempData\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "training_verbosity = 2\n",
    "# Download data if needed and import.\n",
    "mnist = input_data.read_data_sets('tempData', one_hot=True, reshape=False)\n",
    "val_images = mnist.validation.images\n",
    "val_labels = mnist.validation.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:30:48.178696Z",
     "start_time": "2019-04-03T00:30:48.101983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Create LeNet model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6,\n",
    "                 [5, 5],\n",
    "                 input_shape=[28, 28, 1],\n",
    "                 activation='relu',\n",
    "                 name='conv_1'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(16, [5, 5], activation='relu', name='conv_2'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu', name='dense_1'))\n",
    "model.add(Dense(84, activation='relu', name='dense_2'))\n",
    "model.add(Dense(10, activation='softmax', name='dense_3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:30:48.187638Z",
     "start_time": "2019-04-03T00:30:48.180658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         min_delta=0,\n",
    "                                         patience=10,\n",
    "                                         verbose=training_verbosity,\n",
    "                                         mode='auto')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                        factor=0.1,\n",
    "                                        patience=5,\n",
    "                                        verbose=training_verbosity,\n",
    "                                        mode='auto',\n",
    "                                        epsilon=0.0001,\n",
    "                                        cooldown=0,\n",
    "                                        min_lr=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:32:07.227694Z",
     "start_time": "2019-04-03T00:30:48.188638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 0.3307 - acc: 0.9012 - val_loss: 0.1229 - val_acc: 0.9640\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.0934 - acc: 0.9709 - val_loss: 0.0748 - val_acc: 0.9796\n",
      "Epoch 3/5\n",
      " - 16s - loss: 0.0671 - acc: 0.9790 - val_loss: 0.0563 - val_acc: 0.9838\n",
      "Epoch 4/5\n",
      " - 18s - loss: 0.0536 - acc: 0.9832 - val_loss: 0.0593 - val_acc: 0.9844\n",
      "Epoch 5/5\n",
      " - 18s - loss: 0.0433 - acc: 0.9866 - val_loss: 0.0599 - val_acc: 0.9840\n",
      "original model accuracy: 0.984 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train LeNet on MNIST\n",
    "results = model.fit(mnist.train.images,\n",
    "                    mnist.train.labels,\n",
    "                    epochs=5,\n",
    "                    batch_size=128,\n",
    "                    verbose=2,\n",
    "                    validation_data=(val_images, val_labels),\n",
    "                    callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "loss,accuracy_original = model.evaluate(val_images, val_labels, batch_size=128, verbose=2)\n",
    "\n",
    "model.save(\"./LeNet5_test/before_pruning.h5\")\n",
    "print('original model accuracy:', accuracy_original, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:52:08.230555Z",
     "start_time": "2019-04-03T00:32:07.230687Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 3/16 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 1s 236us/step\n",
      "model accuracy after pruning:  0.932 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 18s 336us/step - loss: 0.0497 - acc: 0.9840\n",
      "Epoch 2/5\n",
      "  384/55000 [..............................] - ETA: 19s - loss: 0.0375 - acc: 0.9896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "C:\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 18s 324us/step - loss: 0.0390 - acc: 0.9877\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 17s 307us/step - loss: 0.0335 - acc: 0.9894\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 14s 255us/step - loss: 0.0281 - acc: 0.9908\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 14s 253us/step - loss: 0.0250 - acc: 0.9923\n",
      "5000/5000 [==============================] - 0s 98us/step\n",
      "model accuracy after retraining:  0.9888 \n",
      "\n",
      "Deleting 4/13 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 1s 149us/step\n",
      "model accuracy after pruning:  0.8672 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 17s 312us/step - loss: 0.0401 - acc: 0.9864\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 19s 350us/step - loss: 0.0287 - acc: 0.9905\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 18s 333us/step - loss: 0.0252 - acc: 0.9915\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 19s 337us/step - loss: 0.0205 - acc: 0.9931\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 20s 355us/step - loss: 0.0175 - acc: 0.9942\n",
      "5000/5000 [==============================] - 1s 177us/step\n",
      "model accuracy after retraining:  0.988 \n",
      "\n",
      "Deleting 1/9 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 2s 309us/step\n",
      "model accuracy after pruning:  0.9616 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 20s 358us/step - loss: 0.0246 - acc: 0.9914\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 18s 320us/step - loss: 0.0194 - acc: 0.9932\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 18s 330us/step - loss: 0.0164 - acc: 0.9943\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 15s 277us/step - loss: 0.0165 - acc: 0.9947\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 16s 287us/step - loss: 0.0112 - acc: 0.9963\n",
      "5000/5000 [==============================] - 1s 151us/step\n",
      "model accuracy after retraining:  0.9884 \n",
      "\n",
      "Deleting 1/8 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 1s 249us/step\n",
      "model accuracy after pruning:  0.9512 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 20s 368us/step - loss: 0.0211 - acc: 0.9925\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 18s 335us/step - loss: 0.0157 - acc: 0.9944\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 19s 350us/step - loss: 0.0115 - acc: 0.9961\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 19s 349us/step - loss: 0.0127 - acc: 0.9958\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 17s 310us/step - loss: 0.0125 - acc: 0.9956\n",
      "5000/5000 [==============================] - 1s 168us/step\n",
      "model accuracy after retraining:  0.9866 \n",
      "\n",
      "Deleting 1/7 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 1s 258us/step\n",
      "model accuracy after pruning:  0.968 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 19s 340us/step - loss: 0.0211 - acc: 0.9929\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 18s 335us/step - loss: 0.0140 - acc: 0.9950\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 18s 335us/step - loss: 0.0123 - acc: 0.9958\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 18s 335us/step - loss: 0.0111 - acc: 0.9962\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 19s 339us/step - loss: 0.0102 - acc: 0.9961\n",
      "5000/5000 [==============================] - 1s 169us/step\n",
      "model accuracy after retraining:  0.9884 \n",
      "\n",
      "Deleting 0/6 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 2s 411us/step\n",
      "model accuracy after pruning:  0.9884 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 21s 378us/step - loss: 0.0111 - acc: 0.9963\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 19s 338us/step - loss: 0.0085 - acc: 0.9972\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 18s 330us/step - loss: 0.0100 - acc: 0.9962\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 19s 340us/step - loss: 0.0091 - acc: 0.9971\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 19s 343us/step - loss: 0.0077 - acc: 0.9975\n",
      "5000/5000 [==============================] - 1s 166us/step\n",
      "model accuracy after retraining:  0.9874 \n",
      "\n",
      "Deleting 1/6 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 2s 443us/step\n",
      "model accuracy after pruning:  0.9484 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 22s 395us/step - loss: 0.0270 - acc: 0.9906\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 19s 349us/step - loss: 0.0136 - acc: 0.9953\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 19s 355us/step - loss: 0.0119 - acc: 0.9958\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 19s 347us/step - loss: 0.0084 - acc: 0.9972\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 18s 321us/step - loss: 0.0110 - acc: 0.9962\n",
      "5000/5000 [==============================] - 1s 169us/step\n",
      "model accuracy after retraining:  0.9876 \n",
      "\n",
      "Deleting 1/5 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 2s 326us/step\n",
      "model accuracy after pruning:  0.9652 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 19s 344us/step - loss: 0.0317 - acc: 0.9893\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 18s 330us/step - loss: 0.0181 - acc: 0.9937\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 19s 343us/step - loss: 0.0149 - acc: 0.9947\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 19s 340us/step - loss: 0.0126 - acc: 0.9956\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 19s 344us/step - loss: 0.0106 - acc: 0.9962\n",
      "5000/5000 [==============================] - 1s 171us/step\n",
      "model accuracy after retraining:  0.9878 \n",
      "\n",
      "Deleting 0/4 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 3s 508us/step\n",
      "model accuracy after pruning:  0.9878 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 22s 393us/step - loss: 0.0125 - acc: 0.9957\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 19s 344us/step - loss: 0.0100 - acc: 0.9964\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 19s 340us/step - loss: 0.0087 - acc: 0.9972\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 19s 345us/step - loss: 0.0077 - acc: 0.99721s - loss: 0.00\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 18s 327us/step - loss: 0.0083 - acc: 0.9971\n",
      "5000/5000 [==============================] - 1s 167us/step\n",
      "model accuracy after retraining:  0.9856 \n",
      "\n",
      "Deleting 1/4 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 2s 472us/step\n",
      "model accuracy after pruning:  0.614 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 21s 388us/step - loss: 0.1024 - acc: 0.9701\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 19s 338us/step - loss: 0.0425 - acc: 0.9855\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 19s 341us/step - loss: 0.0305 - acc: 0.9891\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 18s 333us/step - loss: 0.0266 - acc: 0.9905\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 18s 330us/step - loss: 0.0212 - acc: 0.9929\n",
      "5000/5000 [==============================] - 1s 184us/step\n",
      "model accuracy after retraining:  0.985 \n",
      "\n",
      "Deleting 1/3 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 2s 335us/step\n",
      "model accuracy after pruning:  0.7698 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 21s 379us/step - loss: 0.1096 - acc: 0.9639\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 12s 225us/step - loss: 0.0652 - acc: 0.9779\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 13s 232us/step - loss: 0.0527 - acc: 0.9829\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 14s 252us/step - loss: 0.0463 - acc: 0.9845\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 16s 283us/step - loss: 0.0421 - acc: 0.9854\n",
      "5000/5000 [==============================] - 1s 104us/step\n",
      "model accuracy after retraining:  0.981 \n",
      "\n",
      "Deleting 1/2 channels from layer: conv_2\n",
      "5000/5000 [==============================] - 2s 441us/step\n",
      "model accuracy after pruning:  0.5002 \n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 21s 375us/step - loss: 0.2771 - acc: 0.9101\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 18s 328us/step - loss: 0.1757 - acc: 0.9423\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 18s 324us/step - loss: 0.1495 - acc: 0.9507\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 20s 367us/step - loss: 0.1347 - acc: 0.9561\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 19s 349us/step - loss: 0.1245 - acc: 0.9585\n",
      "5000/5000 [==============================] - 1s 212us/step\n",
      "model accuracy after retraining:  0.9632 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer_name = 'conv_2'\n",
    "\n",
    "accuracy = accuracy_original\n",
    "\n",
    "while accuracy > (0.98):\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    apoz = identify.get_apoz(model, layer, val_images)\n",
    "    high_apoz_channels = identify.high_apoz(apoz)\n",
    "    model = delete_channels(model, layer, high_apoz_channels)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    loss,accuracy = model.evaluate(val_images,\n",
    "                          val_labels,\n",
    "                          batch_size=128)\n",
    "\n",
    "    model.save(\"./LeNet5_test/after_pruning.h5\")\n",
    "    print('model accuracy after pruning: ', accuracy, '\\n')\n",
    "\n",
    "\n",
    "    results = model.fit(mnist.train.images,\n",
    "                        mnist.train.labels,\n",
    "                        epochs=5,\n",
    "                        batch_size=128,\n",
    "                        callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    loss,accuracy = model.evaluate(val_images,\n",
    "                          val_labels,\n",
    "                          batch_size=128)\n",
    "    model.save(\"./LeNet5_test/after_pruning_retrain.h5\")\n",
    "    print('model accuracy after retraining: ', accuracy, '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:52:08.246752Z",
     "start_time": "2019-04-03T00:52:08.234583Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "layer_name = 'dense_1'\n",
    "\n",
    "while accuracy > (0.97):\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    apoz = identify.get_apoz(model, layer, val_images)\n",
    "    high_apoz_channels = identify.high_apoz(apoz)\n",
    "    model = delete_channels(model, layer, high_apoz_channels)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    loss,accuracy = model.evaluate(val_images,\n",
    "                          val_labels,\n",
    "                          batch_size=128)\n",
    "\n",
    "    model.save(\"./LeNet5_test/after_pruning_dense1.h5\")\n",
    "    print('model accuracy after pruning: ', accuracy, '\\n')\n",
    "\n",
    "\n",
    "    results = model.fit(mnist.train.images,\n",
    "                        mnist.train.labels,\n",
    "                        epochs=5,\n",
    "                        batch_size=128,\n",
    "                        callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    loss,accuracy = model.evaluate(val_images,\n",
    "                          val_labels,\n",
    "                          batch_size=128)\n",
    "    model.save(\"./LeNet5_test/after_pruning_dense1_retrain.h5\")\n",
    "    print('model accuracy after retraining: ', accuracy, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T00:52:09.305461Z",
     "start_time": "2019-04-03T00:52:08.249744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy after retraining:  0.9632 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(val_images,\n",
    "                          val_labels,\n",
    "                          batch_size=128,\n",
    "                          verbose=2)\n",
    "print('model accuracy after retraining: ', accuracy, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T01:17:57.865558Z",
     "start_time": "2019-04-03T00:52:09.310455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 15/84 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 2s 415us/step\n",
      "model accuracy after pruning:  0.9594 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 19s 345us/step - loss: 0.1213 - acc: 0.9601\n",
      "Epoch 2/5\n",
      "  768/55000 [..............................] - ETA: 10s - loss: 0.0797 - acc: 0.9727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "C:\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 10s 190us/step - loss: 0.1121 - acc: 0.9636\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 10s 190us/step - loss: 0.1053 - acc: 0.9649\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 16s 297us/step - loss: 0.1001 - acc: 0.9670\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 20s 365us/step - loss: 0.0947 - acc: 0.9686\n",
      "5000/5000 [==============================] - 1s 201us/step\n",
      "model accuracy after retraining:  0.9676 \n",
      "\n",
      "Deleting 10/69 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 2s 457us/step\n",
      "model accuracy after pruning:  0.9588 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 18s 323us/step - loss: 0.0963 - acc: 0.9685\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 19s 348us/step - loss: 0.0938 - acc: 0.9689\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 20s 366us/step - loss: 0.0881 - acc: 0.9707\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 18s 326us/step - loss: 0.0850 - acc: 0.9727\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 18s 334us/step - loss: 0.0840 - acc: 0.9723\n",
      "5000/5000 [==============================] - 1s 152us/step\n",
      "model accuracy after retraining:  0.97 \n",
      "\n",
      "Deleting 11/59 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 3s 504us/step\n",
      "model accuracy after pruning:  0.9632 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 22s 399us/step - loss: 0.0877 - acc: 0.9703\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 20s 367us/step - loss: 0.0826 - acc: 0.9727\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 20s 357us/step - loss: 0.0789 - acc: 0.9738\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 20s 362us/step - loss: 0.0771 - acc: 0.9749\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 20s 359us/step - loss: 0.0761 - acc: 0.9749\n",
      "5000/5000 [==============================] - 1s 219us/step\n",
      "model accuracy after retraining:  0.9704 \n",
      "\n",
      "Deleting 5/48 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 2s 486us/step\n",
      "model accuracy after pruning:  0.958 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 22s 399us/step - loss: 0.0796 - acc: 0.9741\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 20s 359us/step - loss: 0.0750 - acc: 0.9751\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 19s 349us/step - loss: 0.0737 - acc: 0.97580s - loss: 0.0736 - a\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 21s 382us/step - loss: 0.0723 - acc: 0.9763\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 19s 341us/step - loss: 0.0705 - acc: 0.9757\n",
      "5000/5000 [==============================] - 1s 221us/step\n",
      "model accuracy after retraining:  0.9746 \n",
      "\n",
      "Deleting 5/43 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 3s 548us/step\n",
      "model accuracy after pruning:  0.9626 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 22s 393us/step - loss: 0.0743 - acc: 0.9753\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 20s 355us/step - loss: 0.0711 - acc: 0.9769\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 20s 361us/step - loss: 0.0697 - acc: 0.9770\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 20s 367us/step - loss: 0.0684 - acc: 0.9772\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 18s 329us/step - loss: 0.0657 - acc: 0.9782\n",
      "5000/5000 [==============================] - 1s 205us/step\n",
      "model accuracy after retraining:  0.9726 \n",
      "\n",
      "Deleting 4/38 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 3s 503us/step\n",
      "model accuracy after pruning:  0.966 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 23s 418us/step - loss: 0.0710 - acc: 0.9760\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 19s 347us/step - loss: 0.0655 - acc: 0.9787\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 19s 351us/step - loss: 0.0660 - acc: 0.9778\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 21s 377us/step - loss: 0.0635 - acc: 0.9791\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 16s 285us/step - loss: 0.0623 - acc: 0.9798\n",
      "5000/5000 [==============================] - 1s 170us/step\n",
      "model accuracy after retraining:  0.968 \n",
      "\n",
      "Deleting 5/34 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 3s 595us/step\n",
      "model accuracy after pruning:  0.926 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 22s 392us/step - loss: 0.0740 - acc: 0.9745\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 19s 351us/step - loss: 0.0675 - acc: 0.9776\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 21s 373us/step - loss: 0.0654 - acc: 0.97790s - loss: 0.0655 - \n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 18s 325us/step - loss: 0.0627 - acc: 0.9791\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 18s 328us/step - loss: 0.0633 - acc: 0.9788\n",
      "5000/5000 [==============================] - 1s 112us/step\n",
      "model accuracy after retraining:  0.9716 \n",
      "\n",
      "Deleting 4/29 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 2s 352us/step\n",
      "model accuracy after pruning:  0.9642 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 19s 345us/step - loss: 0.0697 - acc: 0.9772\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 22s 396us/step - loss: 0.0647 - acc: 0.9790\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 13s 230us/step - loss: 0.0631 - acc: 0.9793\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 16s 299us/step - loss: 0.0617 - acc: 0.9799\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 20s 369us/step - loss: 0.0611 - acc: 0.9803\n",
      "5000/5000 [==============================] - 1s 213us/step\n",
      "model accuracy after retraining:  0.9742 \n",
      "\n",
      "Deleting 1/25 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 3s 561us/step\n",
      "model accuracy after pruning:  0.974 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 23s 416us/step - loss: 0.0625 - acc: 0.9789\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 19s 339us/step - loss: 0.0607 - acc: 0.9799\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 13s 233us/step - loss: 0.0598 - acc: 0.9804\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 12s 212us/step - loss: 0.0603 - acc: 0.9805\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 18s 331us/step - loss: 0.0581 - acc: 0.9808\n",
      "5000/5000 [==============================] - 1s 160us/step\n",
      "model accuracy after retraining:  0.9698 \n",
      "\n",
      "Deleting 2/24 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 3s 596us/step\n",
      "model accuracy after pruning:  0.8946 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 19s 346us/step - loss: 0.0671 - acc: 0.9775\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 18s 327us/step - loss: 0.0606 - acc: 0.9797\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 19s 340us/step - loss: 0.0580 - acc: 0.9810\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 17s 307us/step - loss: 0.0578 - acc: 0.9811\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 17s 306us/step - loss: 0.0575 - acc: 0.9807\n",
      "5000/5000 [==============================] - 1s 174us/step\n",
      "model accuracy after retraining:  0.9708 \n",
      "\n",
      "Deleting 1/22 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 3s 616us/step\n",
      "model accuracy after pruning:  0.9682 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 19s 340us/step - loss: 0.0603 - acc: 0.9800\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 16s 295us/step - loss: 0.0585 - acc: 0.9807\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 16s 283us/step - loss: 0.0559 - acc: 0.9812\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 17s 312us/step - loss: 0.0570 - acc: 0.9814\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 13s 241us/step - loss: 0.0571 - acc: 0.9810\n",
      "5000/5000 [==============================] - 1s 173us/step\n",
      "model accuracy after retraining:  0.9724 \n",
      "\n",
      "Deleting 2/21 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 4s 785us/step\n",
      "model accuracy after pruning:  0.9532 \n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 20s 369us/step - loss: 0.0628 - acc: 0.9791\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 16s 295us/step - loss: 0.0583 - acc: 0.9806\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 17s 302us/step - loss: 0.0565 - acc: 0.9813\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 16s 297us/step - loss: 0.0551 - acc: 0.9813\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 16s 287us/step - loss: 0.0545 - acc: 0.9817\n",
      "5000/5000 [==============================] - 1s 162us/step\n",
      "model accuracy after retraining:  0.9718 \n",
      "\n",
      "Deleting 1/19 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 2s 466us/step\n",
      "model accuracy after pruning:  0.967 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 21s 386us/step - loss: 0.0583 - acc: 0.9807\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 17s 305us/step - loss: 0.0556 - acc: 0.9814\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 19s 340us/step - loss: 0.0561 - acc: 0.9814\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 19s 343us/step - loss: 0.0547 - acc: 0.9817\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 17s 318us/step - loss: 0.0543 - acc: 0.9820\n",
      "5000/5000 [==============================] - 1s 200us/step\n",
      "model accuracy after retraining:  0.9732 \n",
      "\n",
      "Deleting 2/18 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 5s 1ms/step\n",
      "model accuracy after pruning:  0.9414 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 23s 416us/step - loss: 0.0692 - acc: 0.9775\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 18s 336us/step - loss: 0.0609 - acc: 0.9796\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 17s 315us/step - loss: 0.0574 - acc: 0.9806\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 15s 276us/step - loss: 0.0580 - acc: 0.9807\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 16s 299us/step - loss: 0.0561 - acc: 0.9815\n",
      "5000/5000 [==============================] - 1s 157us/step\n",
      "model accuracy after retraining:  0.9718 \n",
      "\n",
      "Deleting 1/16 channels from layer: dense_2\n",
      "5000/5000 [==============================] - 4s 765us/step\n",
      "model accuracy after pruning:  0.954 \n",
      "\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 18s 330us/step - loss: 0.0638 - acc: 0.9785\n",
      "Epoch 2/5\n",
      "46080/55000 [========================>.....] - ETA: 2s - loss: 0.0594 - acc: 0.9801"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-197d085adde8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                         callbacks=[early_stopping, reduce_lr])\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     loss,accuracy = model.evaluate(val_images,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layer_name = 'dense_2'\n",
    "\n",
    "while accuracy > (0.96):\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    apoz = identify.get_apoz(model, layer, val_images)\n",
    "    high_apoz_channels = identify.high_apoz(apoz)\n",
    "    model = delete_channels(model, layer, high_apoz_channels)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    loss,accuracy = model.evaluate(val_images,\n",
    "                          val_labels,\n",
    "                          batch_size=128)\n",
    "\n",
    "    model.save(\"./LeNet5_test/after_pruning_dense2.h5\")\n",
    "    print('model accuracy after pruning: ', accuracy, '\\n')\n",
    "\n",
    "\n",
    "    results = model.fit(mnist.train.images,\n",
    "                        mnist.train.labels,\n",
    "                        epochs=5,\n",
    "                        batch_size=128,\n",
    "                        callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    loss,accuracy = model.evaluate(val_images,\n",
    "                          val_labels,\n",
    "                          batch_size=128)\n",
    "    model.save(\"./LeNet5_test/after_pruning_dense2_retrain.h5\")\n",
    "    print('model accuracy after retraining: ', accuracy, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
