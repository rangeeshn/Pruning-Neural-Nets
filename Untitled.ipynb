{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-a1b5988fa46e>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Pruning Hyperparameters: [('begin_pruning_step', 0), ('block_height', 1), ('block_pooling_function', 'AVG'), ('block_width', 1), ('end_pruning_step', -1), ('initial_sparsity', 0.0), ('name', 'model_pruning'), ('nbins', 256), ('pruning_frequency', 10), ('sparsity_function_begin_step', 0), ('sparsity_function_end_step', 100), ('sparsity_function_exponent', 3), ('target_sparsity', 0.5), ('threshold_decay', 0.0), ('use_tpu', False), ('weight_sparsity_map', [''])]\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\model_pruning\\python\\pruning_utils.py:231: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:tensorflow:Updating masks.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Pruned model step 0 test accuracy 0.0807\n",
      "Weight sparsities: [0.0, 0.0, 0.0]\n",
      "Pruned model step 10 test accuracy 0.2244\n",
      "Weight sparsities: [0.89958334, 0.89783335, 0.89900005]\n",
      "Pruned model step 20 test accuracy 0.3053\n",
      "Weight sparsities: [0.8987075, 0.8980667, 0.89800006]\n",
      "Pruned model step 30 test accuracy 0.3817\n",
      "Weight sparsities: [0.89906466, 0.8998667, 0.89900005]\n",
      "Pruned model step 40 test accuracy 0.4217\n",
      "Weight sparsities: [0.89256805, 0.8983334, 0.89900005]\n",
      "Pruned model step 50 test accuracy 0.4653\n",
      "Weight sparsities: [0.8970706, 0.8967, 0.89900005]\n",
      "Pruned model step 60 test accuracy 0.4977\n",
      "Weight sparsities: [0.89949405, 0.89676666, 0.897]\n",
      "Pruned model step 70 test accuracy 0.5268\n",
      "Weight sparsities: [0.8916369, 0.8966333, 0.89800006]\n",
      "Pruned model step 80 test accuracy 0.58\n",
      "Weight sparsities: [0.89807403, 0.8972, 0.896]\n",
      "Pruned model step 90 test accuracy 0.6227\n",
      "Weight sparsities: [0.8996004, 0.8973, 0.89400005]\n",
      "Pruned model step 100 test accuracy 0.6261\n",
      "Weight sparsities: [0.8882441, 0.89743334, 0.89500004]\n",
      "Pruned model step 110 test accuracy 0.6475\n",
      "Weight sparsities: [0.8984609, 0.8999, 0.89900005]\n",
      "Pruned model step 120 test accuracy 0.6684\n",
      "Weight sparsities: [0.89917094, 0.8983334, 0.89900005]\n",
      "Pruned model step 130 test accuracy 0.6768\n",
      "Weight sparsities: [0.8905358, 0.8991333, 0.89900005]\n",
      "Pruned model step 140 test accuracy 0.6911\n",
      "Weight sparsities: [0.89992774, 0.8991, 0.89900005]\n",
      "Pruned model step 150 test accuracy 0.6968\n",
      "Weight sparsities: [0.896756, 0.8955667, 0.89900005]\n",
      "Pruned model step 160 test accuracy 0.7265\n",
      "Weight sparsities: [0.8985502, 0.8986667, 0.89900005]\n",
      "Pruned model step 170 test accuracy 0.7314\n",
      "Weight sparsities: [0.8977041, 0.8993667, 0.89900005]\n",
      "Pruned model step 180 test accuracy 0.7376\n",
      "Weight sparsities: [0.8964329, 0.89523333, 0.89900005]\n",
      "Pruned model step 190 test accuracy 0.7515\n",
      "Weight sparsities: [0.89761484, 0.8973, 0.89900005]\n",
      "Pruned model step 200 test accuracy 0.7526\n",
      "Weight sparsities: [0.89674747, 0.8976667, 0.89900005]\n",
      "Pruned model step 210 test accuracy 0.7517\n",
      "Weight sparsities: [0.8996854, 0.8973667, 0.89900005]\n",
      "Pruned model step 220 test accuracy 0.7633\n",
      "Weight sparsities: [0.89805275, 0.8973667, 0.89900005]\n",
      "Pruned model step 230 test accuracy 0.7589\n",
      "Weight sparsities: [0.899239, 0.89526665, 0.89900005]\n",
      "Pruned model step 240 test accuracy 0.7746\n",
      "Weight sparsities: [0.8998045, 0.89956665, 0.89900005]\n",
      "Pruned model step 250 test accuracy 0.7818\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 260 test accuracy 0.7836\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 270 test accuracy 0.7849\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 280 test accuracy 0.7861\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 290 test accuracy 0.7883\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 300 test accuracy 0.7903\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 310 test accuracy 0.7929\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 320 test accuracy 0.7954\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 330 test accuracy 0.7971\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 340 test accuracy 0.8\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 350 test accuracy 0.8023\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 360 test accuracy 0.8034\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 370 test accuracy 0.8056\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 380 test accuracy 0.8069\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 390 test accuracy 0.8084\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 400 test accuracy 0.8108\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 410 test accuracy 0.8125\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 420 test accuracy 0.8139\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 430 test accuracy 0.8154\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 440 test accuracy 0.8168\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 450 test accuracy 0.8185\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 460 test accuracy 0.8211\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 470 test accuracy 0.8223\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 480 test accuracy 0.8243\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 490 test accuracy 0.8258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 500 test accuracy 0.8281\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 510 test accuracy 0.8286\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 520 test accuracy 0.83\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 530 test accuracy 0.832\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 540 test accuracy 0.8332\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 550 test accuracy 0.8354\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 560 test accuracy 0.8361\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 570 test accuracy 0.8373\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 580 test accuracy 0.8385\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 590 test accuracy 0.8393\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 600 test accuracy 0.8399\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 610 test accuracy 0.8411\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 620 test accuracy 0.8427\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 630 test accuracy 0.8435\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 640 test accuracy 0.8447\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 650 test accuracy 0.8461\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 660 test accuracy 0.847\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 670 test accuracy 0.848\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 680 test accuracy 0.8496\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 690 test accuracy 0.8505\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 700 test accuracy 0.852\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 710 test accuracy 0.8529\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 720 test accuracy 0.854\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 730 test accuracy 0.8552\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 740 test accuracy 0.8565\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 750 test accuracy 0.8569\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 760 test accuracy 0.858\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 770 test accuracy 0.8595\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 780 test accuracy 0.8606\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 790 test accuracy 0.8612\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 800 test accuracy 0.8622\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 810 test accuracy 0.8625\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 820 test accuracy 0.8636\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 830 test accuracy 0.865\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 840 test accuracy 0.8663\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 850 test accuracy 0.867\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 860 test accuracy 0.8674\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 870 test accuracy 0.8683\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 880 test accuracy 0.8691\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 890 test accuracy 0.8697\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 900 test accuracy 0.8709\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 910 test accuracy 0.8714\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 920 test accuracy 0.8725\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 930 test accuracy 0.8735\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 940 test accuracy 0.8743\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 950 test accuracy 0.8753\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 960 test accuracy 0.876\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 970 test accuracy 0.8764\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 980 test accuracy 0.8769\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Pruned model step 990 test accuracy 0.8777\n",
      "Weight sparsities: [0.8998725, 0.8983334, 0.89900005]\n",
      "Final accuracy: 0.8784\n",
      "Final sparsity by layer (should be 0) [0.8998725, 0.8983334, 0.89900005]\n",
      "Model saved in path: ./model_after_pruning.ckpt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.model_pruning.python import pruning\n",
    "from tensorflow.contrib.model_pruning.python.layers import layers\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 55000 # Entire training set\n",
    "\n",
    "# Import dataset\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "batches = int(len(mnist.train.images) / batch_size)\n",
    "\n",
    "# Define Placeholders\n",
    "image = tf.placeholder(tf.float32, [None, 784])\n",
    "label = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Define the model\n",
    "layer1 = layers.masked_fully_connected(image, 300)\n",
    "layer2 = layers.masked_fully_connected(layer1, 100)\n",
    "logits = layers.masked_fully_connected(layer2, 10)\n",
    "\n",
    "# Create global step variable (needed for pruning)\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "reset_global_step_op = tf.assign(global_step, 0)\n",
    "\n",
    "# Loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=label))\n",
    "\n",
    "# Training op, the global step is critical here, make sure it matches the one used in pruning later\n",
    "# running this operation increments the global_step\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, global_step=global_step)\n",
    "\n",
    "# Accuracy ops\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Get, Print, and Edit Pruning Hyperparameters\n",
    "pruning_hparams = pruning.get_pruning_hparams()\n",
    "print(\"Pruning Hyperparameters:\", pruning_hparams)\n",
    "\n",
    "# Change hyperparameters to meet our needs\n",
    "pruning_hparams.begin_pruning_step = 0\n",
    "pruning_hparams.end_pruning_step = 250\n",
    "pruning_hparams.pruning_frequency = 1\n",
    "pruning_hparams.sparsity_function_end_step = 250\n",
    "pruning_hparams.target_sparsity = .9\n",
    "\n",
    "# Create a pruning object using the pruning specification, sparsity seems to have priority over the hparam\n",
    "p = pruning.Pruning(pruning_hparams, global_step=global_step, sparsity=.9)\n",
    "prune_op = p.conditional_mask_update_op()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    \"\"\"\n",
    "    # Train the model before pruning (optional)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_op, feed_dict={image: batch_xs, label: batch_ys})\n",
    "\n",
    "        # Calculate Test Accuracy every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            acc_print = sess.run(accuracy, feed_dict={image: mnist.test.images, label: mnist.test.labels})\n",
    "            print(\"Un-pruned model step %d test accuracy %g\" % (epoch, acc_print))\n",
    "\n",
    "    acc_print = sess.run(accuracy, feed_dict={image: mnist.test.images, label: mnist.test.labels})\n",
    "    print(\"Pre-Pruning accuracy:\", acc_print)\n",
    "    print(\"Sparsity of layers (should be 0)\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
    "\n",
    "    save_path = saver.save(sess, \"./model_before_pruning.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reset the global step counter and begin pruning\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Prune and retrain\n",
    "            sess.run(prune_op)\n",
    "            sess.run(train_op, feed_dict={image: batch_xs, label: batch_ys})\n",
    "\n",
    "        # Calculate Test Accuracy every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            acc_print = sess.run(accuracy, feed_dict={image: mnist.test.images, label: mnist.test.labels})\n",
    "            print(\"Pruned model step %d test accuracy %g\" % (epoch, acc_print))\n",
    "            print(\"Weight sparsities:\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
    "\n",
    "    # Print final accuracy\n",
    "    acc_print = sess.run(accuracy, feed_dict={image: mnist.test.images, label: mnist.test.labels})\n",
    "    print(\"Final accuracy:\", acc_print)\n",
    "    print(\"Final sparsity by layer (should be 0)\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
    "    \n",
    "    save_path = saver.save(sess, \"./model_after_pruning.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
